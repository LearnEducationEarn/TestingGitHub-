import cv2
import os
import numpy as np
from ultralytics import YOLO

# –ü—ä—Ç –¥–æ –ø–∞–ø–∫–∞—Ç–∞ —Å –≤–∏–¥–µ–∞
video_folder = "C:/Videos"  # —Å–º–µ–Ω–∏ —Å —Ç–≤–æ—è—Ç–∞ –ø–∞–ø–∫–∞
log_file = "results.txt"

# –ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ YOLOv8 –º–æ–¥–µ–ª
model = YOLO("yolov8n.pt")  # –ª–µ–∫ –∏ –±—ä—Ä–∑ –º–æ–¥–µ–ª

def analyze_frame(frame):
    results = model(frame)[0]
    labels = [model.names[i] for i in results.boxes.cls]

    has_person = "person" in labels
    has_car = any(label in labels for label in ["car", "truck", "bus", "motorbike"])

    # –ó–∞—Å–∏—á–∞–Ω–µ –Ω–∞ —Å–≤–µ—Ç–ª–∏–Ω–∞
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    brightness = np.mean(gray)
    light_detected = brightness > 100

    return has_person, has_car, light_detected

with open(log_file, "w", encoding="utf-8") as log:
    for filename in os.listdir(video_folder):
        if filename.endswith(".mp4") or filename.endswith(".avi"):
            path = os.path.join(video_folder, filename)
            cap = cv2.VideoCapture(path)

            person_found = False
            car_found = False
            light_found = False

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break

                has_person, has_car, light = analyze_frame(frame)

                person_found |= has_person
                car_found |= has_car
                light_found |= light

            cap.release()

            # –§–∏–ª—Ç—Ä–∏—Ä–∞–Ω–µ: –∑–∞–ø–∏—Å–≤–∞–º–µ —Å–∞–º–æ –∞–∫–æ –∏–º–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç
            if person_found or car_found or light_found:
                log.write(f"{filename}: üë§ —á–æ–≤–µ–∫={person_found}, üöó –∫–æ–ª–∞={car_found}, üí° —Å–≤–µ—Ç–ª–∏–Ω–∞={light_found}\n")
                print(f"{filename}: ‚úÖ —á–æ–≤–µ–∫={person_found}, –∫–æ–ª–∞={car_found}, —Å–≤–µ—Ç–ª–∏–Ω–∞={light_found}")

print("üîç –ê–Ω–∞–ª–∏–∑—ä—Ç –µ –∑–∞–≤—ä—Ä—à–µ–Ω.")
